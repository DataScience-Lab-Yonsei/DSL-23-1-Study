{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "- Data definiton\n",
        "- Hypothesis\n",
        "- Compute loss (손실 계산) \n",
        "- Gradient descent (경사하강법) "
      ],
      "metadata": {
        "id": "194B-Hhtnt4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "aYips0TepcTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data define - 입력, 출력 tensor필요\n",
        "\n"
      ],
      "metadata": {
        "id": "mbaREHk_qbdR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peLy4r1lnRp2"
      },
      "outputs": [],
      "source": [
        "x_train = torch.FloatTensor([[1], [2], [3]]) # 공부한 시간\n",
        "y_train = torch.FloatTensor([[2], [4], [6]]) # 점수"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# hypothsis\n",
        "\n",
        "$ y = Wx + b $\n",
        "\n",
        "W와 B를 구해서 가장 적합한 직선을 구하고자 함\n",
        "\n",
        "W는 가중치 ( Weight ) \n",
        "\n",
        "b는 편향 ( bias ) "
      ],
      "metadata": {
        "id": "vEFie5nMp2db"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W = torch.zeros(1, requires_grad=True) # 0으로 초기화, requires_grad = T ; 학습할것임. \n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "\n",
        "hypothesis = x_train * W + b"
      ],
      "metadata": {
        "id": "tedfePW8rl5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Compute loss\n",
        "\n",
        "MSE를 통해 loss 계산"
      ],
      "metadata": {
        "id": "rp9OqVl5xDZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cost function = loss function = error function = objective function"
      ],
      "metadata": {
        "id": "SLH6yLZjqQlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$ cost(W, b) = \\frac{1}{m} \\sum^m_{i=1} \\left( H(x^{(i)}) - y^{(i)} \\right)^2 $$"
      ],
      "metadata": {
        "id": "qrxglbTIxjDm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$H(x)$가 $y$를 얼마나 잘 예측했는가\n",
        "\n",
        "cost가 작으면 좋은 예측\n"
      ],
      "metadata": {
        "id": "CoYIgv84y3e8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cost = torch.mean((hypothesis - y_train) ** 2)  \n",
        "cost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPcREO47ql_q",
        "outputId": "433451c6-7951-4fc4-ded8-f3d2485b4bfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(18.6667, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hypothesis - y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsYpmLbBqmEZ",
        "outputId": "24c12b6f-8459-4570-998e-4f6506b84000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.],\n",
              "        [-4.],\n",
              "        [-6.]], grad_fn=<SubBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Descent (경사하강법)\n",
        "\n",
        "모델 개선\n",
        "\n",
        "cost를 최소로 하는 W와 b를 찾기 위함임.\n",
        "\n",
        "cost function을 미분하여 현재 $W$에서의 접선의 기울기를 구하고 접선의 기울기가 낮은 방향으로 $W$값을 변경하는 작업을 반복함. \n",
        "\n",
        "접선의 기울기가 0일 때 cost가 최솟값이 되고, 이 때의 W, b를 찾아야함. \n",
        "\n",
        "W, b 와 cost는 이차함수관계"
      ],
      "metadata": {
        "id": "TcCyrZhxzlkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD([W, b], lr=0.01) # 학습시킬 tensor : [W,b], learning rate = 0.01 (임의)"
      ],
      "metadata": {
        "id": "D0FREIbbzjnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer.zero_grad()  #미분으로 얻은 gradient 0으로 초기화. 파이토치는 미분으로 얻은 기울기를 계속 누적하는 특징이 있기 때문\n",
        "cost.backward()   # W, b에 대한 gradient 계산\n",
        "optimizer.step()  #W, b 업데이트 (Gradient Descent)"
      ],
      "metadata": {
        "id": "ACV0OzTxzzNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "55dXHUY1N2SS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# full code\n"
      ],
      "metadata": {
        "id": "moEZ7vrJIHJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터\n",
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[2], [4], [6]])\n",
        "\n",
        "# 모델 초기화\n",
        "W = torch.zeros(1, requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "h \n",
        "\n",
        "# optimizer 정의\n",
        "optimizer = optim.SGD([W, b], lr=0.01)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    hypothesis = x_train * W + b\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad() #backword로 기울기를 구하기 전에 그 전에 구했던 값은 0으로 초기화\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(W, b, cost)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qujvbHDdzzQK",
        "outputId": "3544fbfd-7640-44d8-aadf-973021d487b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.9709], requires_grad=True) tensor([0.0663], requires_grad=True) tensor(0.0006, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6EiNBccXzzT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2t-E9TLVzzWp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}